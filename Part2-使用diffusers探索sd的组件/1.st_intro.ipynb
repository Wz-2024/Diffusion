{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-16T16:01:28.456991400Z",
     "start_time": "2024-09-16T16:01:28.338683500Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mrequests\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mPIL\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Image\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from matplotlib import pyplot as plt\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import os\n",
    "\n",
    "from torch.utils.tensorboard.summary import image\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6841cb7919569bc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T14:45:33.266379700Z",
     "start_time": "2024-09-14T14:45:29.420055100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load the PipeLine\n",
    "model_id = \"/data_disk/dyy/stable-diffusion-2\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, revision=\"fp16\", torch_dtype=torch.float16).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcee7699bdbcf702",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T14:46:08.899139100Z",
     "start_time": "2024-09-14T14:45:34.975157Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Set up a generator for reproducibility\n",
    "generator = torch.Generator(device=device).manual_seed(60)\n",
    "#Run the pipeline,showing some of the available arguments\n",
    "pipe_output = pipe(\n",
    "    prompt='ghibli style yellow dog',\n",
    "    #negative_prompt='Oversaturated,blurry,low quality',\n",
    "    height=480, width=640,\n",
    "    guidance_scale=8,  #这里默认是7.5\n",
    "    num_inference_steps=999,\n",
    "    generator=generator\n",
    ")\n",
    "\n",
    "#View the resulting image:\n",
    "pipe_output.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94144d155da9740",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T06:10:04.609847400Z",
     "start_time": "2024-09-13T06:09:46.600243900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#image with different guidance_scale\n",
    "cfg_scales = [1.1, 8, 10]\n",
    "prompt = 'a dead man'\n",
    "fig, axs = plt.subplots(1, len(cfg_scales), figsize=(15, 15))\n",
    "for i, ax in enumerate(axs):\n",
    "    im = pipe(\n",
    "        prompt,\n",
    "        height=480, width=480,\n",
    "        guidance_scale=cfg_scales[i],\n",
    "        num_inference_steps=200,\n",
    "        generator=torch.Generator(device=device).manual_seed(88)).images[0]\n",
    "\n",
    "    ax.imshow(im)\n",
    "    ax.set_title(f'cfg={cfg_scales[i]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a0628629b95ebf",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# PipeLine Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dedf4c7f4d41c9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T06:10:04.619748400Z",
     "start_time": "2024-09-13T06:10:04.609847400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(list(pipe.components))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f6275c3073fc29",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccef23945a1245bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T06:10:04.619748400Z",
     "start_time": "2024-09-13T06:10:04.609847400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#将原图片压缩,经过VAE进入到隐空间, 再从隐空间解码成图片  这就是VAE的过程\n",
    "images = torch.rand(1, 3, 512, 512).to(device) * 2 - 1  #可以映射到[-1,1]\n",
    "images = images.to(torch.float16)\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e986dd2071460eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T06:10:04.619748400Z",
     "start_time": "2024-09-13T06:10:04.609847400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    latents = 0.18215 * pipe.vae.encode(images).latent_dist.mean  #latent_distribution\n",
    "    #0.18215是训练diffusion时用到的Normalization的缩放系数scaling factor,将[-1,1]->(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7351d262544a14cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T06:10:04.619748400Z",
     "start_time": "2024-09-13T06:10:04.609847400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#查看Pipe的组件,,或者pipe组件的组件\n",
    "#pipe.vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c67e6ac29b3a261",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T06:10:04.619748400Z",
     "start_time": "2024-09-13T06:10:04.609847400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Decode again\n",
    "with torch.no_grad():\n",
    "    decode_images = pipe.vae.decode(latents / 0.18215).sample\n",
    "print('Decoded images shape:', decode_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4fc72381941d8e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# The Tokenizer(分词器) and Text Encoder\n",
    "一个input_prompt会被分词器分词,然后输入到text encoder,得到一个text embedding(1,77,1024)  77表示最大长度<br>\n",
    "它的作用就是将文本转化为向量,输入到UNet中,作为约束条件<br>\n",
    "Tokenizer将文本转换为一个个词的id,token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4177e833fee373",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T06:10:04.619748400Z",
     "start_time": "2024-09-13T06:10:04.619748400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Tikenize\n",
    "input_ids = pipe.tokenizer(['A painting of a dog'])['input_ids']\n",
    "\n",
    "print('Input ID -> decode token')\n",
    "for input_id in input_ids[0]:\n",
    "    print(f'{input_id} -> {pipe.tokenizer.decode(input_id)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47506915a79aa4f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T06:10:04.619748400Z",
     "start_time": "2024-09-13T06:10:04.619748400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Feed through CLIP text encoder\n",
    "input_ids = torch.tensor(input_ids).to(device)\n",
    "print(pipe.text_encoder(input_ids)['last_hidden_state'].shape)\n",
    "print(pipe.text_encoder(input_ids)['pooler_output'].shape)  # 池化后的 [1, 1024]\n",
    "\n",
    "with torch.no_grad():\n",
    "    text_embeddings = pipe.text_encoder(input_ids)['last_hidden_state']\n",
    "print('test embeddings shape:', text_embeddings.shape)\n",
    "\n",
    "# Get the final text embeddings using the pipeline's _encode_prompt function\n",
    "# 自行生成 prompt_embeds\n",
    "prompt_embeds = pipe.text_encoder(input_ids)['last_hidden_state']\n",
    "text_embeddings = pipe.encode_prompt(\n",
    "    prompt=None,  # 因为我们已经提供了 prompt_embeds\n",
    "    device=device,\n",
    "    num_images_per_prompt=1,\n",
    "    do_classifier_free_guidance=False,\n",
    "    prompt_embeds=prompt_embeds,  # 使用手动生成的 prompt_embeds\n",
    ")[0]\n",
    "\n",
    "\n",
    "print(text_embeddings.shape)\n",
    "#这里输出[1, 77, 1024],表示即便当前不够77的长度,也会填充0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce423c8963b941d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0b348fd762bd2fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T06:10:04.619748400Z",
     "start_time": "2024-09-13T06:10:04.619748400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dummy inputs:\n",
    "timestep=pipe.scheduler.timesteps[0]\n",
    "latents=torch.randn(1,4,64,64).to(device).half()\n",
    "text_embeddings=torch.randn(1,77,1024).to(device).half()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a05ab60145e952",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T06:10:04.830263400Z",
     "start_time": "2024-09-13T06:10:04.619748400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model prediction\n",
    "with torch.no_grad():\n",
    "    unet_output = pipe.unet(latents, timestep, text_embeddings).sample\n",
    "print('UNet output shape:', unet_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dcda2ebbbbd31c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1731b7221684985b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T06:10:04.830263400Z",
     "start_time": "2024-09-13T06:10:04.671589300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#画出alphas(这里给出的是cumulative production,πalpha[i]表示保有原图的多少)\n",
    "#画出betas(表示noise的强度)\n",
    "plt.plot(pipe.scheduler.alphas_cumprod,label=r'$\\bar{\\alpha}$')\n",
    "plt.xlabel('Timestep (from high noise to low noise')\n",
    "plt.title('Noise schedule')\n",
    "plt.show()\n",
    "# 从图像可以看出,从高噪声到低噪声,alpha的值逐渐减小,表示保留原始图像的程度小,也就是越来越趋于全噪声"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbc37f8b50f9728",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T06:10:06.605645200Z",
     "start_time": "2024-09-13T06:10:04.734529600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# swapping scheduler\n",
    "from diffusers import LMSDiscreteScheduler\n",
    "\n",
    "# Replace the scheduler\n",
    "pipe.scheduler = LMSDiscreteScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "# Print the config\n",
    "print('Scheduler config:', pipe.scheduler)\n",
    "\n",
    "# Generate an image with this new scheduler\n",
    "pipe(prompt=\"Palette knife painting of an winter cityscape\", height=480, width=480,\n",
    "     generator=torch.Generator(device=device).manual_seed(42)).images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b6a3d6f0aca0f8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## DIY Text2Image Sampling Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56a9fc8776bff2e",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d00572b9f79fb2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T06:10:06.605645200Z",
     "start_time": "2024-09-13T06:10:06.605645200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
